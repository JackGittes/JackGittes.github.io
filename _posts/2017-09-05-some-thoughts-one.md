---
title: 深度神经网络压缩的小总结
category: 网络压缩
author: 赵明心
excerpt: |
  写这篇文章总结一下常见的深度神经网络压缩优化的概念和方法，不对现有的文献做详细的对比和介绍，只是为了方便日后看文献时能理清思路。
use_math: true
#feature_text: |
  ## The Pot Still
#  The modern pot still is a descendant of the alembic, an earlier distillation device
#feature_image: "https://unsplash.it/1200/400?image=1048"
#image: "https://unsplash.it/1200/400?image=1048"
---

### 优化方法分类

#### 分类标准1
　　目前的神经网络优化压缩从优化方法使用的时间上可以分为“从头开始优化”和“预训练再优化”两种。

　　这两种方法希望实现的目标是一致的，那就是在不改动原来网络结构(层数、每层的类型、每层神经元的规模)的情况下，压缩网络参数和减少计算操作次数，与此同时尽可能保持原来网络的精度。现在也出现了一些在层(layer)这个级别进行剪枝的优化方法，这样会在一定程度上修改网络结构，但基本想法还是相似的，就是要有一个已经存在的网络结构作为参照进行优化。

　　举个例子，如果我要优化一个在ImageNet上训练的VGG-16网络。“从头开始优化”一般是在原来VGG-16的损失函数中添加网络复杂度的惩罚项，然后扔到ImageNet上初始化参数以后重新训练一次，从而获得一个复杂度低参数少的网络。或者是直接在VGG-16重新训练的过程中使用剪枝、dropout、权重量化等方法进行压缩。

　　而“预训练再优化”会把一个在ImageNet上已经训练好的VGG-16的参数拿来，然后利用设置阈值剪枝、低秩逼近、量化共享等方法对权重参数进行修改，再用修改后的参数作为网络的初始化参数进行“微调训练”(fine-tune，称为“微调”是因为这个过程中参数的变化幅度相比直接从头训练要小很多，收敛也会快很多)。当然也可以是利用训练好的参数，在fine-tune过程中进行动态优化。

　　“预训练再优化”和“从头开始优化”相比，好处是优化过程往往比较简单，因为有了已经训练好的网络参数作为起点，所以优化算法一般收敛较快，适用的网络种类也较多。但缺点也恰恰是由于“预训练再优化”要依赖于已经训练好的网络参数，导致它有时不能很好地从根本上去除网络参数设计上的冗余。

### 一种数学解释

　　在缺乏深度神经网络其他先验知识的情况下，“预训练再优化”的方法基本都要做到在减少参数数目的同时，能在数值上逼近原来的参数矩阵。这是因为我们无法利用其他更有价值的信息(例如在损失函数里增加复杂度惩罚)来发掘网络的冗余性，所以只能从数值计算结果的角度来考虑，也即必须保证优化后的权重矩阵和输入向量相乘的结果，跟原矩阵与输入向量相乘的结果相差很小。

　　如果我们把优化前的权重矩阵记作$W$，优化后的矩阵记作$W'$，$W$这一层的输入向量记为$x$，那么之前的问题用数学语言表述一下就是：

$$minimize\  \  \  \  ||Wx-W'x||$$

再用绝对值不等式放缩一下，问题就简化为：

$$minimize\  \  \  \  ||W-W'||$$

　　这其实就是一个矩阵逼近问题。奇异值分解、权重量化能成为常见而有效的压缩方法正是因为它们能在减少参数数目或者参数分布复杂度的情况下又在很大程度上逼近原来权重矩阵的数值特征。

　　这点也是从头开始(From scratch)训练神经网络进行压缩和先pretrain一个网络然后再压缩的一点小区别。从头开始训练的话，可以在Loss里面增加一些对网络复杂度的惩罚项，也可以在训练过程中通过Dropout或者剪枝等方法实现稀疏化，这样得到的参数矩阵可能跟直接训练得到的参数矩阵在数值特点上都大不相同。而pretrain网络之后再做优化，得到的参数矩阵往往是参数变少而矩阵和输入向量相乘的结果跟优化前的差别较小。




---