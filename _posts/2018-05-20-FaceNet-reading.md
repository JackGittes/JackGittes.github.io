---
title: |
      FaceNet:A Unified Embedding for Face Recognition and Clustering
category: 神经网络
author: 赵明心
excerpt: |
 这是谷歌在2015年发表于CVPR的论文，文章提出了一种使用神经网络进行度量学习的方法，并将构造的神经网络用于人脸识别，在LFW数据集上达到了当时的state-of-the-art水平。
use_math: true
#feature_text: |
  ## The Pot Still
#  The modern pot still is a descendant of the alembic, an earlier distillation device
#feature_image: "https://unsplash.it/1200/400?image=1048"
#image: "https://unsplash.it/1200/400?image=1048"
---

### 一、简介
度量学习是为了直接从数据样本中学得一种相似度的度量方式(也即一种度量空间，在这个空间中的距离直接与样本的相似性有关)。谷歌提出的FaceNet通过训练一个深度神经网络，使得神经网络的输出(一个n维的向量)直接对应于输入样本在度量空间中的表示。文章指出，FaceNet可以直接学习到一种从人脸图片到一个紧欧氏空间的映射关系。

和传统神经网络使用的交叉熵损失不同，FaceNet使用了三元组损失(Triplet Loss)，这也是FaceNet能够学得一种度量的重要原因。使用了三元组损失之后，FaceNet不再需要像之前的自编码器等神经网络一样，必须要通过一个瓶颈层才能获得样本的低维嵌入表示，而是直接可以输出低维表示。

文章的主要创新点即在于：
- 使用了三元组损失(Triplet Loss)而不是传统的交叉熵损失来构造网络的损失函数
- 网络可以直接学到从样本空间到一个紧欧氏空间的映射关系
- 网络直接输出样本的低维表示，而不再需要从中间的瓶颈层中提取，训练过程是端到端的

### 二、背景与引言
这个网络可以用一个架构实现三种任务：人脸验证(验证两张脸是否是同一个人)，人脸识别(识别人脸属于数据库中的哪个人)，聚类(将相似的人脸归为一类)。关键就在于他们直接使用了深度神经网络来学习一个欧氏距离，一旦训练完成，每个人脸样本对应的输出向量之间的距离就直接和人脸的相似度有关。


### 三、实现细节

#### 3.1 网络结构

#### 3.2 三元组损失
计算一个三元组损失需要三个样本，其中一个样本被称为“Anchor”，另一个样本与“Anchor”来自同一个人脸，被称为“Positive(正样本)”，最后一个样本来自其他人的人脸，为“Negative(负样本)”。三元组损失就被定义为：

$$L=\sum_{i}^{N}[||f(x_i^a)-f(x_i^p)||^2-||f(x_i^a)-f(x_i^n)||^2+\alpha]$$

#### 3.3 三元组的构造方法
三元组构造的核心是选择“难分”的正样本和负样本，所谓“难分”是指到Anchor距离很大的正样本或者到Anchor距离很小的负样本。这些样本容易产生错误的分类结果，训练时的关键就是优化“难分”样本的向量表示。如果在构造训练数据的时候，尽可能多的选择“难分”样本来构成“Anchor、Positive、Negative”三元组会加快收敛速度(因为易分类样本的三元组损失本来就小，不会对模型参数更新产生大的影响)。

文章提出了离线和在线两种构造三元组的方法：

- 离线方法：训练网络，每N步中止一次，利用当前网络给出的距离度量来选择难分的正负样本组成三元组
- 在线方法：在训练过程当中，直接在每个小batch里选择最难分的正负样本构成三元组

当然也可以把离线和在线方法进行混合使用，作者认为这样做有可能加快算法收敛速度，但是没有得到实验验证。

#### 3.4 训练方法和过程
作者使用了传统的随机梯度下降法(SGD)对网络进行训练

### 四、实验结果

### 五、总结与结论